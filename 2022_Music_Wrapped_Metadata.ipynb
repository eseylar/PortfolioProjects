{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eseylar/PortfolioProjects/blob/main/2022_Music_Wrapped_Metadata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqfuVjtDEWZs"
      },
      "outputs": [],
      "source": [
        "#IMPORTING AND INSTALLING LIBRARIES\n",
        "\n",
        "#install musicbrainz library (music metadata source)\n",
        "!pip install musicbrainzngs\n",
        "\n",
        "#import libraries\n",
        "import musicbrainzngs as mb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas.core.api import isnull\n",
        "import json\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9zSzoFpmx2z"
      },
      "outputs": [],
      "source": [
        "#SETTING USER AGENT (app name, version, contact info) -- required to contact api\n",
        "\n",
        "mb.set_useragent('My 2022 in Music Wrapped', '0.2', contact=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "En-B2vIgoP6g"
      },
      "outputs": [],
      "source": [
        "#IMPORTING LISTENING DATA (all 2022 Spotify music streams)\n",
        "df = pd.read_csv('listening_2022.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VlnSRlIol9R"
      },
      "source": [
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alP3Mk6qrFQH"
      },
      "outputs": [],
      "source": [
        "#TRUNCATING DATAFRAME\n",
        "\n",
        "#Note: It takes several hours to execute this code over all 8491 rows in the data frame due to speed limitations set by the MusicBrainz API. \n",
        "#      To work around this, I established code to limit the dataframe to 1000 rows at a time to run the code in smaller chunks. At the end, I merge them into one dataframe again.\n",
        "#      In order to change my set of rows, I just copy/paste the appropriate index into hard brackets on line 20 of this code chunk, \n",
        "#      Once I finish exporting a completed datafram, I run this code with the next index of dataframe rows. Rinse and Repeat.\n",
        "\n",
        "#indexing code chunks\n",
        "#[0:1000] rows 0-999\n",
        "#[1000:2000] rows 1000-1999\n",
        "#[2000:3000] rows 2000-2999\n",
        "#[3000:4000] rows 3000-3999\n",
        "#[4000:5000] rows 4000-4999\n",
        "#[5000:6000] rows 5000-5999\n",
        "#[6000:7000] rows 6000-6999\n",
        "#[7000:8000] rows 7000-7999\n",
        "#[8000:8491] rows 8000-8490\n",
        "\n",
        "df = pd.read_csv('listening_2022.csv')\n",
        "df = df.iloc[0:1000] #insert apprporiate chunk inside the hard brackets to the left\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YglK7DoGAKdO"
      },
      "outputs": [],
      "source": [
        "#ADDING GENRE AND DURATION DATA TO DATAFRAME\n",
        "\n",
        "\n",
        "#Counter to run program just once\n",
        "count = 1 \n",
        "\n",
        "#Set empty lists for each new piece of info from Music Brainz, to latter be added back to the dataframe\n",
        "#Original dataframe\n",
        "genre_metadata = []\n",
        "dur_metadata = []\n",
        "artist_id_metadata = []\n",
        "song_id_metadata = []\n",
        "\n",
        "\n",
        "\n",
        "#New dataframe for song_id and genre (to make another table)\n",
        "song_genre_df = pd.DataFrame(columns=['a', 'b']) #new dataframe for song_id and genre (new line for each genre)\n",
        "\n",
        "#New lists to populate with new information for the genre dataframe\n",
        "song_id_genre_df = [] #song_id to be added to df\n",
        "genre_genre_df = [] #genre to be added to df\n",
        "song_genre_data = [] #empty list to add each loop item to , to later be \n",
        "\n",
        "\n",
        "bad_chars = ' ' #space is 'bad character' to be replaced in my genres list; this allows me to later separate a genre string by ' ' delmiiter\n",
        "\n",
        "\n",
        "while count != 2: #looper running loop just once\n",
        "\n",
        "    for ind in df.index: #for each row in the original dataframe of my listening history\n",
        "\n",
        "        artist = df['artist'][ind] #variable artist = the record in the row's artist column\n",
        "        song = df['song'][ind] #variable song = the record in the row's song column\n",
        "        album = df['album'][ind] #variable album = the record in the row's album column\n",
        "\n",
        "        genre_list = [] #set an empty list for genres to go into \n",
        "        dur_list = [] # set an empty list for duration\n",
        "        \n",
        "        artist_list = mb.search_artists(query=artist)['artist-list'] #query music brain using the artist from the datafram as keyword\n",
        "        try: #in case of error\n",
        "            artist_info = artist_list[0] #select the first item from musicbrainz's list, the artist whose name best matches the queried artist name\n",
        "        except IndexError:\n",
        "            pass\n",
        "\n",
        "\n",
        "        #Generate artist_id\n",
        "        try: #incase of artist_info error, this try block will add a null to the relevant metadata rather than stop the code with an error\n",
        "            artist_id = artist_info['id']\n",
        "        except:\n",
        "            artist_id = None\n",
        "\n",
        "        artist_id_metadata.append(artist_id)\n",
        "\n",
        "\n",
        "        #Generate duration\n",
        "        recording_list = mb.search_recordings(query=song, limit=1, offset=None, strict=False, artist=artist, release=album) #search for the track in musicbrainz library\n",
        "        try: #if duration is available, pull duration in milliseconds; if not, set dur to None-type\n",
        "            dur = recording_list['recording-list'][0]['length'] #select the length in milliseconds of the track\n",
        "            dur = int(dur) / 1000 #duration in seconds, rather than milliseconds\n",
        "        except:\n",
        "            dur = None\n",
        "\n",
        "        dur_metadata.append(dur)\n",
        "\n",
        "\n",
        "        #Generate song_id\n",
        "        song_id = recording_list['recording-list'][0]['id']\n",
        "\n",
        "        song_id_metadata.append(song_id)\n",
        "\n",
        "\n",
        "        #Generate genre list\n",
        "        genre_counter = 0 #counter so script can query a variable amount of genres\n",
        "        try:\n",
        "            for item in artist_info['tag-list']: #for each genre tagged in the artist profile...\n",
        "                \n",
        "                if int(artist_info['tag-list'][genre_counter]['count']) > 0: #if the 'count' element is greater than 0 (basically, if people haven't downvoted the tag)...\n",
        "                    new_genre = artist_info['tag-list'][genre_counter]['name'] #set that genre's name to the variable new_genre...\n",
        "                                  \n",
        "                    #replace ' ' with '-'\n",
        "                    for i in bad_chars:\n",
        "                        new_genre = new_genre.replace(i, '-')\n",
        "\n",
        "\n",
        "                    #Generating song_id and genre for the genre table\n",
        "                    song_id_genre_df.append(song_id) #add song_id to the list \n",
        "                    genre_genre_df.append(new_genre) #add the new genre to the list\n",
        "\n",
        "                    song_genre_data.append([song_id, new_genre]) #add new row of data with song_id and genre\n",
        "                    \n",
        "                    \n",
        "                    #Adding genre to a list for the original dataframe\n",
        "                    genre_list.append(new_genre) #add the new genre to the list\n",
        "                    genre_counter += 1 #add one to the counter to move to next item in 'tag-list'\n",
        "                else: #if the 'count' is 0 or negative....\n",
        "                    genre_counter += 1 #add one to the counter to move to next item in 'tag-list', don't save that genre to list\n",
        "        except:\n",
        "            new_genre = None #if there are no genre tags, set the genre to None-type\n",
        "            genre_list.append(new_genre)\n",
        "\n",
        "        genre_metadata.append(genre_list)\n",
        "\n",
        "\n",
        "        time.sleep(0.02) #added delay; Musicbrainz throttles queries past 50 per second\n",
        "\n",
        "    count += 1 #add one to overall counter/looper\n",
        "\n",
        "#Adding blank columns to the scrobble dataframe (original dataset)\n",
        "df[\"genre\"] = np.nan #create a new data frame column called genre, fill it with NaN-type\n",
        "df[\"duration\"] = np.nan #create a new data frame column called duration, fill it with NaN-type\n",
        "df[\"artist_id\"] = np.nan #create a new data frame column called artist_id, fill it with NaN-type\n",
        "df[\"song_id\"] = np.nan #create a new data frame column called artist_id, fill it with NaN-type\n",
        "\n",
        "#Add series data to the scrobble dataframe, overwriting blank columns just added\n",
        "df = df.assign(genre = genre_metadata) # fill the genre column with the genre data previously generated\n",
        "df = df.assign(duration = dur_metadata) # fill the duration column with the duration data previously generated\n",
        "df = df.assign(artist_id = artist_id_metadata) # fill the aritst_id column with the artist_id data previously generated\n",
        "df = df.assign(song_id = song_id_metadata) # fill the song_id column with the song_id data previously generated\n",
        "\n",
        "#Add song_id and genre to the genre dataframe (then do some work to rename and reorganinze dataframe, which wouldn't let me append properly)\n",
        "song_genre_df = song_genre_df.append(song_genre_data, )\n",
        "song_genre_df.rename( columns={0 :'song_id'}, inplace=True )\n",
        "song_genre_df.rename( columns={1 :'genre'}, inplace=True )\n",
        "song_genre_df.drop(['a', 'b'], axis=1, inplace=True)\n",
        "\n",
        "display(df) #Show original scrobble dataframe\n",
        "display(song_genre_df) #Show song_id and genre dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubAj3uBQGMgi"
      },
      "outputs": [],
      "source": [
        "#EXPORTING DATAFRAMES AS .CSV FILES\n",
        "#Note: Since I ran this code in small chunks of 1000 rows, I needed code to export each dataframe with a different naming schemea.\n",
        "#      To execute, comment all but the appropriate code chunk and run the cell. \n",
        "\n",
        "#Code Chunk no. 1 -- rows 0-999 (index 0:1000)\n",
        "df.to_csv('scrobbles_0_999.csv', index=False) #scrobble dataframe - rows 0-999\n",
        "song_genre_df.to_csv('genres_0_999.csv', index=False) #genre table dataframe rows 0-999\n",
        "\n",
        "#Code Chunk no. 2 -- rows 1000-1999 (index 1000:2000)\n",
        "df.to_csv('scrobbles_1000_1999.csv', index=False) #scrobble dataframe - rows 1000-1999\n",
        "song_genre_df.to_csv('genres_1000_1999.csv', index=False) #genre table dataframe rows 1000-1999\n",
        "\n",
        "#Code Chunk no. 3 -- rows 2000-2999 (index 2000:3000)\n",
        "df.to_csv('scrobbles_2000_2999.csv', index=False) #scrobble dataframe - rows 2000-2999\n",
        "song_genre_df.to_csv('genres_2000_2999.csv', index=False) #genre table dataframe rows 2000-2999\n",
        "\n",
        "#Code Chunk no. 4 -- rows 3000-3999 (index 3000:4000)\n",
        "df.to_csv('scrobbles_3000_3999.csv', index=False) #scrobble dataframe - rows 3000-3999\n",
        "song_genre_df.to_csv('genres_3000_3999.csv', index=False) #genre table dataframe rows 3000-3999\n",
        "\n",
        "#Code Chunk no. 5 -- rows 4000-4999 (index 4000:5000)\n",
        "df.to_csv('scrobbles_4000_4999.csv', index=False) #scrobble dataframe - rows 4000-4999\n",
        "song_genre_df.to_csv('genres_4000_4999.csv', index=False) #genre table dataframe rows 4000-4999\n",
        "\n",
        "#Code Chunk no. 6 -- rows 5000-5999 (index 5000:6000)\n",
        "df.to_csv('scrobbles_5000_5999.csv', index=False) #scrobble dataframe - rows 5000-5999\n",
        "song_genre_df.to_csv('genres_5000_5999.csv', index=False) #genre table dataframe rows 5000-5999\n",
        "\n",
        "#Code Chunk no. 7 -- rows 6000-6999 (index 6000:7000)\n",
        "df.to_csv('scrobbles_6000_6999.csv', index=False) #scrobble dataframe - rows 6000-6999\n",
        "song_genre_df.to_csv('genres_6000_6999.csv', index=False) #genre table dataframe rows 6000-6999\n",
        "\n",
        "#Code Chunk no. 8 -- rows 7000-7999 (index 7000:8000)\n",
        "df.to_csv('scrobbles_7000_7999.csv', index=False) #scrobble dataframe - rows 7000-7999\n",
        "song_genre_df.to_csv('genres_7000_7999.csv', index=False) #genre table dataframe rows 7000-7999\n",
        "\n",
        "#Code Chunk no. 9 -- rows 8000-8490 (index 8000:8490)\n",
        "df.to_csv('scrobbles_8000_8490.csv', index=False) #scrobble dataframe - rows 8000-8490\n",
        "song_genre_df.to_csv('genres_8000_8490.csv', index=False) #genre table dataframe rows 8000-8490"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concatenating Smaller Dataframes"
      ],
      "metadata": {
        "id": "Bsvw-4EWozLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CONCAT FULL SCROBBLE DATA\n",
        "\n",
        "df0 = pd.read_csv('scrobbles_0_999.csv')\n",
        "df1000 = pd.read_csv('scrobbles_1000_1999.csv')\n",
        "df2000 = pd.read_csv('scrobbles_2000_2999.csv')\n",
        "df3000 = pd.read_csv('scrobbles_3000_3999.csv')\n",
        "df4000 = pd.read_csv('scrobbles_4000_4999.csv')\n",
        "df5000 = pd.read_csv('scrobbles_5000_5999.csv')\n",
        "df6000 = pd.read_csv('scrobbles_6000_6999.csv')\n",
        "df7000 = pd.read_csv('scrobbles_7000_7999.csv')\n",
        "df8000 = pd.read_csv('scrobbles_8000_8490.csv')\n",
        "\n",
        "full_scrobble_df = pd.concat([df0, df1000, df2000, df3000, df4000, df5000, df6000, df7000, df8000], axis=0, ignore_index=True)\n",
        "\n",
        "full_scrobble_df.to_csv('full_scrobble_data_2022.csv', index=False)"
      ],
      "metadata": {
        "id": "4nMHIeGupBY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CONCAT GENRE TABLE\n",
        "\n",
        "g0 = pd.read_csv('genres_0_999.csv')\n",
        "g1000 = pd.read_csv('genres_1000_1999.csv')\n",
        "g2000 = pd.read_csv('genres_2000_2999.csv')\n",
        "g3000 = pd.read_csv('genres_3000_3999.csv')\n",
        "g4000 = pd.read_csv('genres_4000_4999.csv')\n",
        "g5000 = pd.read_csv('genres_5000_5999.csv')\n",
        "g6000 = pd.read_csv('genres_6000_6999.csv')\n",
        "g7000 = pd.read_csv('genres_7000_7999.csv')\n",
        "g8000 = pd.read_csv('genres_8000_8490.csv')\n",
        "\n",
        "full_genre_df = pd.concat([g0, g1000, g2000, g3000, g4000, g5000, g6000, g7000, g8000], axis=0, ignore_index=True)\n",
        "\n",
        "full_genre_df.to_csv('full_genre_data_2022.csv', index=False)"
      ],
      "metadata": {
        "id": "ytiRGvPKpGjf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVW+X9CK+Qr0ZOcy3gp65Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}